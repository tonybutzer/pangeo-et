{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare time series extraction COG Data\n",
    "Using Xarray, Rasterio and Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import dask\n",
    "from dask.distributed import Client, progress\n",
    "#from dask_kubernetes import KubeCluster\n",
    "import os\n",
    "import fsspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `fsspec` to explore an S3 \"requester pays\" bucket like a filesystem.  We don't actually pay anything here since the USGS Pangeo and the data being read here live in the same AWS region (us-west-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=False, requester_pays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all the COGS for a given year\n",
    "def get_tifs(year):\n",
    "    files = fs.ls(f'dev-et-data/test/compressed/NDVI_filled/{year}')\n",
    "    return [f for f in files if f.endswith('tif')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dask cluster.  We can run KubeCluster on pangeo, but for rasterio to be able to read from \"requester pays\" buckets we need to set an environment variable and pass it to the workers also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_REQUEST_PAYER\"] = \"requester\" \n",
    "##cluster = KubeCluster(n_workers=8, env={'AWS_REQUEST_PAYER': 'requester'})\n",
    "#client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.close()\n",
    "# local client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(512*512*4)*(10)/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a delayed function to return an xarray dataarray from a tif filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def tif_to_da(tif):\n",
    "    return xr.open_rasterio('s3://'+tif, chunks={'band':1, 'x':512, 'y':512})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data array for first 30 yeardays of a given year (just reading metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tifs = get_tifs(2001)\n",
    "lazy_da =[tif_to_da(tif) for tif in tifs[:180]]\n",
    "dalist = dask.compute(*lazy_da)\n",
    "da = xr.concat(dalist, dim='band')\n",
    "da = da.rename({'band':'yearday'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign values to the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = da.assign_coords(yearday=range(0,180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = da.to_dataset(name='ndvi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.isel(x=slice(20480,20480+1024), y=slice(1024,2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds.ndvi[:,0,0].load().hvplot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.chunk(chunks={'yearday':10, 'x':512, 'y':512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ndvi.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ndvi.encoding = {'chunks': (10,512,512)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.ndvi[0,0,0].load().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to zarr using my \"s3\" aws credentionals profile\n",
    "\n",
    "d = fsspec.get_mapper('s3://chs-pangeo-data-bucket/rsignell/zarr/zarr_test', \n",
    "                                    anon=False, profile='s3')\n",
    "ds.load().to_zarr(store=d, mode='w', consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  open and read rechunked zarr data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dszs3 = xr.open_zarr(fsspec.get_mapper('s3://chs-pangeo-data-bucket/rsignell/zarr/zarr_test', \n",
    "                                    anon=False, profile='s3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dszs3.ndvi[:,0,0].load().hvplot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom Line: for this test and this toolset, it's 20 times faster reading the rechunked zarr compared to original COGS!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
